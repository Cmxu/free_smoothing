{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_util import toDeviceDataLoader, load_cifar, to_device, load_mnist\n",
    "from model_util import VGG\n",
    "import torchvision\n",
    "from util import dsa\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')\n",
    "\n",
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNet, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(28*28, 100)\n",
    "        self.l2 = torch.nn.Linear(100, 50)\n",
    "        self.l3 = torch.nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.l1(x))\n",
    "        out = torch.relu(self.l2(out))\n",
    "        return self.l3(out)\n",
    "\n",
    "mdl = to_device(MNet(), device)\n",
    "mdl.load_state_dict(torch.load('./models/torch_mnist_net.pth'))\n",
    "mdl = mdl.eval()\n",
    "\n",
    "# mdl = to_device(MNet(), device)\n",
    "# crit = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01) \n",
    "# for epoch in range(10):\n",
    "#     pbar = tqdm(train_loader)\n",
    "#     for batch_id, (images, labels) in enumerate(pbar):  \n",
    "#         outputs = mdl(images.view(-1, 28*28))\n",
    "#         loss = F.cross_entropy(outputs, labels)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step() \n",
    "#         if batch_id == len(train_loader) - 1:\n",
    "#             pbar.set_postfix({\"Test Accuracy\":dsa(test_loader, mdl)})\n",
    "# torch.save(mdl.state_dict(), \"models/torch_mnist_net.pth\")\n",
    "\n",
    "train_loader, test_loader = load_mnist(64, 10, device)\n",
    "# mdl = to_device(VGG('VGG16'), device)\n",
    "# mdl.load_state_dict(torch.load('./models/torch_cifar_vgg.pth'))\n",
    "# mdl = mdl.eval()\n",
    "\n",
    "# dataset_root = '/share/datasets/cifar10'\n",
    "# cifar10_train, cifar10_val, cifar10_test = load_cifar(dataset_root)\n",
    "# train_loader, val_loader, test_loader = toDeviceDataLoader(cifar10_train, cifar10_val, cifar10_test, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnmean_(alphas):\n",
    "    less = - np.sqrt(2/np.pi) * torch.exp(-(alphas ** 2)/2) / (torch.erf(alphas/np.sqrt(2)) - 1)\n",
    "    more = np.sqrt(2/np.pi) / torch.special.erfcx(alphas/np.sqrt(2))\n",
    "    res = torch.where(alphas <= 0, less, more)\n",
    "    return torch.max(alphas, res)\n",
    "\n",
    "def tnmean(means, stds, mins):\n",
    "    alphas = (mins - means)/stds\n",
    "    return means + tnmean_(alphas) * stds\n",
    "\n",
    "def tnmom2(alphas):\n",
    "    return 1 + np.sqrt(2/np.pi) * alphas / torch.special.erfcx(alphas/np.sqrt(2))\n",
    "\n",
    "def tnvar_(alphas):\n",
    "    m1 = tnmean_(alphas)\n",
    "    m2 = torch.sqrt(tnmom2(alphas))\n",
    "    return (m2 - m1) * (m2 + m1)\n",
    "\n",
    "def tnvar(means, stds, mins):\n",
    "    alphas = (mins - means)/stds\n",
    "    return tnvar_(alphas) * (stds ** 2)\n",
    "\n",
    "def tnmv(means, stds, mins): # 448 µs ± 4.93 µs vs. 781 µs ± 2 µs\n",
    "    alphas = (mins - means)/stds\n",
    "    aerfcx = torch.special.erfcx(alphas/np.sqrt(2))\n",
    "    aerf = torch.erf(alphas/np.sqrt(2))\n",
    "    mean_adjs = torch.max(alphas, np.sqrt(2/np.pi) * torch.where(alphas <= 0, - torch.exp(-(alphas ** 2)/2)/(aerf - 1), 1/aerfcx))\n",
    "    m2 = torch.sqrt(1 + np.sqrt(2/np.pi) * alphas / aerfcx)\n",
    "    var_adjs = (m2 - mean_adjs)/(m2 + mean_adjs)\n",
    "    return torch.sum(means + mean_adjs * stds, dim = -1), torch.sum(var_adjs * (stds ** 2), dim = -1)\n",
    "\n",
    "def gaussian_cdf(means, variances):\n",
    "    return (1 + torch.erf(-means/(torch.sqrt(variances) * np.sqrt(2))))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncGaussianPMTensor:\n",
    "    def __init__(self, means: torch.Tensor, stds: torch.Tensor, mnormxs = None, pm_sizes = None, pm_locs = None, pm_tot_sizes = None, bounded = False):\n",
    "        self.batch_size = means.shape[0]\n",
    "        self.tensor_shape = means.shape[1:]\n",
    "        self.means = means\n",
    "        self.bounded = bounded\n",
    "        if isinstance(stds, float):\n",
    "            self.stds = stds * torch.ones_like(self.means, device = means.device)\n",
    "        else:\n",
    "            self.stds = stds\n",
    "        if mnormxs is None:\n",
    "            self.mins = torch.zeros_like(self.means, device = means.device)\n",
    "            self.pm_sizes = torch.tensor([])\n",
    "            self.pm_locs = torch.tensor([])\n",
    "            self.pm_tot_sizes = torch.tensor([])\n",
    "        else: \n",
    "            self.mnormxs = mnormxs\n",
    "            self.pm_sizes = pm_sizes\n",
    "            self.pm_locs = pm_locs\n",
    "            self.pm_tot_sizes = pm_tot_sizes\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'N{}({}, {}, {}, {}, {})'.format('b' if self.bounded else '', self.means, self.stds, self.mnormxs, self.pm_sizes, self.pm_locs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return TruncGaussianPMTensor(self.means[key: key + 1], self.stds[key: key + 1], self.mnormxs[key: key + 1], self.pm_sizes[key: key + 1], self.pm_locs[key: key + 1], self.pm_tot_sizes[key: key + 1], self.bounded)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        self.mins = - self.mnormxs\n",
    "        self.maxs = - self.maxs\n",
    "        self.means = - self.means\n",
    "        self.pm_locs = - self.pm_locs\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            raise TypeError(f\"Unsupported addition of two '{self.__class__}'\")\n",
    "        elif isinstance(other, (int, float)):\n",
    "            return TruncGaussianPMTensor(self.means + other, self.stds, self.mnormxs, self.pm_sizes, self.pm_locs + other if len(self.pm_locs) > 0 else self.pm_locs, self.pm_tot_sizes, self.bounded)\n",
    "        elif isinstance(other, torch.Tensor):\n",
    "            #assert other.shape == self.tensor_shape\n",
    "            return TruncGaussianPMTensor(self.means + other, self.stds, self.mnormxs, self.pm_sizes, self.pm_locs + other.view(1, other.shape[0], 1).repeat((self.batch_size, 1, self.pm_locs.shape[2])) if len(self.pm_locs) > 0 else self.pm_locs, self.pm_tot_sizes, self.bounded)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported operand type(s) for +/-: '{self.__class__}' and '{type(other)}'\")\n",
    "    __radd__ = __add__\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return self + -other\n",
    "    def __rsub__(self, other):\n",
    "        return -self + other\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, (int, float, torch.Tensor)):\n",
    "            raise NotImplementedError\n",
    "            #return TruncGaussianPMTensor(other * self.means, other * self.stds, other * self.mins, self.pm_sizes, other * self.pm_locs, self.pm_tot_sizes)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported operand type(s) for *: '{self.__class__}' and '{type(other)}'\")\n",
    "    __rmul__ = __mul__\n",
    "\n",
    "    def __matmul__(self, other):\n",
    "        if isinstance(other, torch.Tensor):\n",
    "            assert len(self.tensor_shape) == 1\n",
    "            if torch.all(self.mins == - float(\"Inf\")):\n",
    "                return TruncGaussianPMTensor(self.means @ other.T, self.stds @ other.T, torch.zeros_like([self.batch_size, other.shape[0]], device = self.mins.device), self.pm_sizes, self.pm_locs, self.pm_tot_sizes, self.bounded)\n",
    "            else:\n",
    "                temp_means = torch.cat([(self.means[:,i:i+1] * other[:,i]).unsqueeze(2) for i in range(self.tensor_shape[0])], dim = 2)\n",
    "                temp_stds = torch.cat([(self.stds[:,i:i+1] * other[:,i]).unsqueeze(2) for i in range(self.tensor_shape[0])], dim = 2)\n",
    "                other_sign = torch.sign(other)\n",
    "                temp_mins = torch.cat([(self.mins[:,i:i+1] * torch.where(other_sign[])).unsqueeze(2) for i in range(self.tensor_shape[0])], dim = 2)\n",
    "                self.temp_means = temp_means\n",
    "                self.temp_stds = temp_stds\n",
    "                self.temp_mins = temp_mins\n",
    "                means, variances = tnmv(temp_means, temp_stds, temp_mins)\n",
    "                stds = torch.sqrt(variances)\n",
    "                #print(temp_means.sum(dim = 2)[0,0])\n",
    "                #print(means[0,0])\n",
    "                mins = - float(\"Inf\") * torch.ones_like(means)\n",
    "                # if self.pm_sizes.shape[2] == 1:\n",
    "                #     print('hi')\n",
    "                #     return TruncGaussianPMTensor(means, variances, mins, self.pm_sizes, self.pm_locs, self.pm_tot_sizes)\n",
    "                # else:\n",
    "                pm_locs = torch.einsum('ijk, lj -> ilkj', self.pm_locs, other).reshape(self.batch_size, means.shape[1], -1)\n",
    "                pm_sizes = self.pm_sizes.permute(0, 2, 1).unsqueeze(1).repeat(1, means.shape[1], 1, 1).reshape(self.batch_size, means.shape[1], -1)/self.tensor_shape[0]\n",
    "                pm_tot_sizes = torch.sum(self.pm_tot_sizes, dim = 1, keepdim = True).repeat(1, means.shape[1])/self.tensor_shape[0]\n",
    "                return TruncGaussianPMTensor(means, stds, mins, pm_sizes, pm_locs, pm_tot_sizes)\n",
    "                #means = torch.cat([(self.means[:,i:i+1] * other[:,i]).unsqueeze(1) for i in range(self.tensor_shape[0])], dim = 1)\n",
    "                #variances = torch.cat([(self.variances[:,i:i+1] * (other[:,i] ** 2)).unsqueeze(1) for i in range(self.tensor_shape[0])], dim = 1)\n",
    "                #mins = torch.cat([(self.mins[:,i:i+1] * other[:,i]).unsqueeze(1) for i in range(self.tensor_shape[0])], dim = 1)\n",
    "                #return TruncGaussianPMTensor(means, variances, mins, self.pm_sizes, self.pm_locs, self.pm_tot_sizes)\n",
    "\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported operand type(s) for *: '{self.__class__}' and '{type(other)}'\")\n",
    "    \n",
    "    def flatten(self):\n",
    "        return TruncGaussianPMTensor(self.means.view(self.batch_size, -1), self.stds.view(self.batch_size, -1), self.mins.view(self.batch_size, -1), self.pm_sizes.view(self.batch_size, -1), self.pm_locs.view(self.batch_size, -1), self.tot_sizes)\n",
    "    \n",
    "    def relu(self):\n",
    "        gcdf = gaussian_cdf(self.means, self.stds)\n",
    "        if len(self.pm_sizes) == 0:\n",
    "            pm_sizes = gcdf.unsqueeze(2)\n",
    "            pm_locs = torch.zeros_like(pm_sizes)\n",
    "            pm_tot_sizes = gcdf\n",
    "        else:\n",
    "            pm_pos_sizes = torch.where(self.pm_locs > 0, self.pm_sizes, 0)\n",
    "            pm_neg_sizes = torch.where(self.pm_locs > 0, 0, self.pm_sizes)\n",
    "            pm_zero = (torch.sum(pm_neg_sizes, dim = 2) + gcdf * (1 - self.pm_tot_sizes)).unsqueeze(2)\n",
    "            pm_sizes = torch.cat((pm_pos_sizes, pm_zero), dim = 2)\n",
    "            pm_locs = torch.cat((self.pm_locs, torch.zeros_like(pm_zero)), dim = 2)\n",
    "            pm_tot_sizes = self.pm_tot_sizes + gcdf * (1 - self.pm_tot_sizes)\n",
    "        return TruncGaussianPMTensor(self.means, self.stds, torch.relu(self.mins), pm_sizes, pm_locs, pm_tot_sizes)\n",
    "\n",
    "    def sample(self, N):\n",
    "        normals = torch.max(self.mins.unsqueeze(2).expand([*self.means.shape, N]), self.stds.unsqueeze(2).expand([*self.means.shape, N]) * torch.randn([*self.means.shape, N], device = self.means.device) + self.means.unsqueeze(2).expand([*self.means.shape, N]))\n",
    "        if len(self.pm_sizes) == 0:\n",
    "            return normals\n",
    "        if torch.all(self.mins == -float('Inf')):\n",
    "            fixed_pm_sizes = torch.cat((self.pm_sizes[:,:,:-1], torch.where(self.pm_sizes.sum(dim = 2) == 0, 1, self.pm_sizes[:,:,-1]).unsqueeze(2)), dim = 2)\n",
    "            pm_tot_sizes = self.pm_tot_sizes\n",
    "        else:\n",
    "            if self.pm_sizes.shape[2] == 1:\n",
    "                pm_tot_sizes = torch.zeros_like(self.pm_tot_sizes)\n",
    "                fixed_pm_sizes = torch.ones_like(self.pm_sizes)\n",
    "            else:\n",
    "                gcdf = gaussian_cdf(self.means, self.variances)\n",
    "                #pm_tot_sizes = self.pm_tot_sizes\n",
    "                pm_tot_sizes = (self.pm_tot_sizes - gcdf)/(1-gcdf)\n",
    "                adj_pm_sizes = torch.cat((self.pm_sizes[:,:,:-1], (self.pm_sizes[:,:,-1] - gcdf * (1 - pm_tot_sizes)).unsqueeze(2)), dim = 2)\n",
    "                fixed_pm_sizes = torch.cat((adj_pm_sizes[:,:,:-1], torch.where(adj_pm_sizes.sum(dim = 2) == 0, 1, adj_pm_sizes[:,:,-1]).unsqueeze(2)), dim = 2)\n",
    "        pm_idx = torch.multinomial(fixed_pm_sizes.reshape(-1, self.pm_sizes.shape[2]), N, replacement = True).reshape(self.batch_size, self.tensor_shape[0], -1)\n",
    "        pms = self.pm_locs[torch.arange(self.batch_size).reshape(self.batch_size, 1, 1).repeat(1, self.tensor_shape[0], N), torch.arange(self.tensor_shape[0]).reshape(1, self.tensor_shape[0], 1).repeat(self.batch_size, 1, N), pm_idx]\n",
    "        #gpm_ratio = torch.rand([*self.means.shape, N], device = self.means.device)\n",
    "        #return torch.where(gpm_ratio > pm_tot_sizes.unsqueeze(2).expand([*self.means.shape, N]), normals, pms)\n",
    "        return torch.sum((self.pm_sizes * self.pm_locs), dim = 2, keepdim = True).expand([*self.means.shape, N]) + normals * (1 - pm_tot_sizes.unsqueeze(2).expand([*self.means.shape, N]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.view(-1, 28*28).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TruncGaussianPMTensor(means = x, variances = 0.1)\n",
    "t1 = t @ mdl.l1.weight + mdl.l1.bias\n",
    "t1r = t1.relu()\n",
    "t2w = t1r @ mdl.l2.weight\n",
    "t2 = t2w + mdl.l2.bias\n",
    "t2r = t2.relu()\n",
    "t3 = t2r @ mdl.l3.weight + mdl.l3.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mdl(mdl, x, variance, i, j, N = 10000, level = None):\n",
    "    if level == '1w':\n",
    "        print(((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T).shape)\n",
    "        return torch.tensor([((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T)[i][j] for _ in range(N)])\n",
    "    elif level == '1':\n",
    "        return torch.tensor([((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T + mdl.l1.bias)[i][j] for _ in range(N)])\n",
    "    elif level == '1r':\n",
    "        return torch.tensor([torch.relu((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T + mdl.l1.bias)[i][j] for _ in range(N)])\n",
    "    elif level == '2w':\n",
    "        return torch.tensor([(torch.relu((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T + mdl.l1.bias) @ mdl.l2.weight.T)[i][j] for _ in range(N)])\n",
    "    elif level == '2':\n",
    "        return torch.tensor([(torch.relu((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T + mdl.l1.bias) @ mdl.l2.weight.T + mdl.l2.bias)[i][j] for _ in range(N)])\n",
    "    elif level == '2r':\n",
    "        return torch.tensor([torch.relu(torch.relu((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T + mdl.l1.bias) @ mdl.l2.weight.T + mdl.l2.bias)[i][j] for _ in range(N)])\n",
    "    elif level == '3w':\n",
    "        return torch.tensor([(torch.relu(torch.relu((x + np.sqrt(variance) * torch.randn_like(x)) @ mdl.l1.weight.T + mdl.l1.bias) @ mdl.l2.weight.T + mdl.l2.bias) @ mdl.l3.weight.T)[i][j] for _ in range(N)])\n",
    "    else:\n",
    "        return torch.tensor([mdl(x + np.sqrt(variance) * torch.randn_like(x))[i][j] for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2w_samples = t2w.sample(10000)[0,0].cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2w_samples = sample_mdl(x, 0.1, 0, 0, 10000, '2w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a66e8ba48cdbbce869fdf53f12a35ac0596a9611ede1f91a83135635f6bc0a12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
